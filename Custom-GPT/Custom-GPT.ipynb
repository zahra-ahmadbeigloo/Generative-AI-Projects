{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"},
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Custom GPT**"
      ],
      "metadata": {
        "id": "_54Bpzb0gIDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install numpy==1.26.0\n",
        "# !pip install torch==2.2.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
        "# !pip install torchtext==0.17.2\n",
        "# !pip install torchdata==0.7.1\n",
        "# !pip install portalocker==2.8.2\n",
        "!pip install pandas==2.2.1\n",
        "# !pip install matplotlib==3.9.0 scikit-learn==1.5.0\n",
        "# !pip install transformers==4.31.0"
      ],
      "metadata": {
        "id": "VVjRDPdugkvR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b8e17fd-d6f2-4494-8d1e-ede91cfd0d13"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas==2.2.1 in /usr/local/lib/python3.11/dist-packages (2.2.1)\n",
            "Requirement already satisfied: numpy<2,>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.1) (1.26.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.1) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.1) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.1) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from typing import Iterable, List\n",
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Transformer\n",
        "from torch import Tensor\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.optim import Adam\n",
        "\n",
        "from torchtext.datasets import multi30k, Multi30k\n",
        "from torchtext.vocab import Vocab\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.datasets import IMDB,PennTreebank\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "\n",
        "\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "LcwHa9sHgnDQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "oUoAswNQNpbP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Kg_M3__JgEI7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a09a6a2b-b745-4df6-c00d-20f42fa021de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1,\n",
              " 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "train_iter, val_iter = IMDB()\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "data_itr=iter(train_iter)\n",
        "next(data_itr)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing Data"
      ],
      "metadata": {
        "id": "tdW9PmHJOW6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "UNK_IDX, PAD_IDX, EOS_IDX = 0, 1, 2\n",
        "special_symbols = ['<unk>', '<pad>', '<|endoftext|>' ]\n",
        "\n",
        "tokenizer = get_tokenizer(\"basic_english\")"
      ],
      "metadata": {
        "id": "ROKarSJ6OV_B"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def yield_tokens(data_iter):\n",
        "    for _,data_sample in data_iter:\n",
        "        yield  tokenizer(data_sample)\n",
        "\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=special_symbols, special_first=True)\n",
        "vocab.set_default_index(UNK_IDX)"
      ],
      "metadata": {
        "id": "bNGWd27TOrug"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_to_index=lambda text: [vocab(token) for token in tokenizer(text)]\n",
        "index_to_en = lambda seq_en: \" \".join([vocab.get_itos()[index] for index in seq_en])\n",
        "\n",
        "index_to_en(torch.tensor([0,1,2]))"
      ],
      "metadata": {
        "id": "LwdHXiZsgONm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "f97b42c9-094f-4177-8e62-ab5d80b6dfb3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<unk> <pad> <|endoftext|>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Collate Function"
      ],
      "metadata": {
        "id": "sSfG__qZPmsm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sample(block_size, text):\n",
        "    # Determine the length of the input text\n",
        "    sample_leg = len(text)\n",
        "    # Calculate the stopping point for randomly selecting a sample\n",
        "    # This ensures the selected sample doesn't exceed the text length\n",
        "    random_sample_stop = sample_leg - block_size\n",
        "\n",
        "\n",
        "    # Check if a random sample can be taken (if the text is longer than block_size)\n",
        "    if random_sample_stop >= 1:\n",
        "        # Randomly select a starting point for the sample\n",
        "        random_start = torch.randint(low=0, high=random_sample_stop, size=(1,)).item()\n",
        "        # Define the endpoint of the sample\n",
        "        stop = random_start + block_size\n",
        "\n",
        "        # Create the input and target sequences\n",
        "        src_sequence = text[random_start:stop]\n",
        "        tgt_sequence= text[random_start + 1:stop + 1]\n",
        "\n",
        "    # Handle the case where the text length is exactly equal or less the block size\n",
        "    elif random_sample_stop <= 0:\n",
        "        # Start from the beginning and use the entire text\n",
        "        random_start = 0\n",
        "        stop = sample_leg\n",
        "        src_sequence= text[random_start:stop]\n",
        "        tgt_sequence = text[random_start + 1:stop]\n",
        "        # Append an empty string to maintain sequence alignment\n",
        "        tgt_sequence.append( '<|endoftext|>')\n",
        "\n",
        "    return src_sequence, tgt_sequence"
      ],
      "metadata": {
        "id": "Gz25zJCNPof_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize empty lists to store source and target sequences\n",
        "src_batch, tgt_batch = [], []\n",
        "block_size=10\n",
        "\n",
        "# Define the batch size\n",
        "BATCH_SIZE = 2\n",
        "\n",
        "# Loop to create batches of source and target sequences\n",
        "for i in range(BATCH_SIZE):\n",
        "    # Retrieve the next data point from the training iterator\n",
        "    _,text = next(iter(train_iter))\n",
        "\n",
        "    # Generate source and target sequences using the get_sample function\n",
        "    src_sequence_text, tgt_sequence_text = get_sample(block_size, tokenizer(text))\n",
        "\n",
        "    # Convert source and target sequences to tokenized vocabulary indices\n",
        "    src_sequence_indices = vocab(src_sequence_text)\n",
        "    tgt_sequence_indices = vocab(tgt_sequence_text)\n",
        "\n",
        "    # Convert the sequences to PyTorch tensors with dtype int64\n",
        "    src_sequence = torch.tensor(src_sequence_indices, dtype=torch.int64)\n",
        "    tgt_sequence = torch.tensor(tgt_sequence_indices, dtype=torch.int64)\n",
        "\n",
        "    # Append the source and target sequences to their respective batches\n",
        "    src_batch.append(src_sequence)\n",
        "    tgt_batch.append(tgt_sequence)\n",
        "\n",
        "    # Print the output for every 2nd sample (adjust as needed)\n",
        "    print(f\"Sample {i}:\")\n",
        "    print(\"Source Sequence (Text):\", src_sequence_text)\n",
        "    print(\"Source Sequence (Indices):\", src_sequence_indices)\n",
        "    print(\"Source Sequence (Shape):\", src_sequence.shape)\n",
        "    print(\"Target Sequence (Text):\", tgt_sequence_text)\n",
        "    print(\"Target Sequence (Indices):\", tgt_sequence_indices)\n",
        "    print(\"Target Sequence (Shape):\", tgt_sequence.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqOizejJSUKm",
        "outputId": "54f9df6d-df81-48ea-a9f8-18a8141aa50d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 0:\n",
            "Source Sequence (Text): ['in', 'the', 'film', 'is', 'shown', 'for', 'artistic', 'purposes', 'rather', 'than']\n",
            "Source Sequence (Indices): [14, 4, 25, 11, 693, 20, 1668, 4919, 253, 82]\n",
            "Source Sequence (Shape): torch.Size([10])\n",
            "Target Sequence (Text): ['the', 'film', 'is', 'shown', 'for', 'artistic', 'purposes', 'rather', 'than', 'just']\n",
            "Target Sequence (Indices): [4, 25, 11, 693, 20, 1668, 4919, 253, 82, 45]\n",
            "Target Sequence (Shape): torch.Size([10])\n",
            "Sample 1:\n",
            "Source Sequence (Text): ['making', 'some', 'sort', 'of', 'documentary', 'on', 'what', 'the', 'average', 'swede']\n",
            "Source Sequence (Indices): [233, 55, 398, 9, 814, 28, 54, 4, 753, 22750]\n",
            "Source Sequence (Shape): torch.Size([10])\n",
            "Target Sequence (Text): ['some', 'sort', 'of', 'documentary', 'on', 'what', 'the', 'average', 'swede', 'thought']\n",
            "Target Sequence (Indices): [55, 398, 9, 814, 28, 54, 4, 753, 22750, 207]\n",
            "Target Sequence (Shape): torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BLOCK_SIZE=30\n",
        "def collate_batch(batch):\n",
        "    src_batch, tgt_batch = [], []\n",
        "    for _,_textt in batch:\n",
        "      src_sequence,tgt_sequence=get_sample(BLOCK_SIZE,tokenizer(_textt))\n",
        "      src_sequence=vocab(src_sequence)\n",
        "      tgt_sequence=vocab(tgt_sequence)\n",
        "      src_sequence= torch.tensor(src_sequence, dtype=torch.int64)\n",
        "      tgt_sequence = torch.tensor(tgt_sequence, dtype=torch.int64)\n",
        "      src_batch.append(src_sequence)\n",
        "      tgt_batch.append(tgt_sequence)\n",
        "\n",
        "\n",
        "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX, batch_first=False)\n",
        "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX, batch_first=False)\n",
        "\n",
        "    return src_batch.to(DEVICE), tgt_batch.to(DEVICE)"
      ],
      "metadata": {
        "id": "yGo0vgXASdw-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE=1\n",
        "dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n",
        "val_dataloader= DataLoader(val_iter , batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)"
      ],
      "metadata": {
        "id": "RBJjycv-SiCI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=iter(dataloader)\n",
        "for sample in range(2):\n",
        "  src,trt=next(dataset)\n",
        "  print(\"sample\",sample)\n",
        "  print(\"sorce:\",index_to_en(src))\n",
        "  print(\"\\n\")\n",
        "  print(\"target:\",index_to_en(trt))\n",
        "  print(\"\\n\")\n",
        "  print(trt.shape)\n",
        "  print(src.shape)\n",
        "  print(\"\\n\")\n"
      ],
      "metadata": {
        "id": "1u9MGVCyWEE_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23a86110-2b2e-442e-9dea-b778399c1f5d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample 0\n",
            "sorce: right from the start . this is not a movie that i liked . i didn ' t hate it in the way of some movies that insult your intelligence\n",
            "\n",
            "\n",
            "target: from the start . this is not a movie that i liked . i didn ' t hate it in the way of some movies that insult your intelligence ,\n",
            "\n",
            "\n",
            "torch.Size([30, 1])\n",
            "torch.Size([30, 1])\n",
            "\n",
            "\n",
            "sample 1\n",
            "sorce: of the worst movies i have ever seen . the dialogue is ghastly , the horror effects are laughable . the only thing that kept me watching was the ever-splendid\n",
            "\n",
            "\n",
            "target: the worst movies i have ever seen . the dialogue is ghastly , the horror effects are laughable . the only thing that kept me watching was the ever-splendid and\n",
            "\n",
            "\n",
            "torch.Size([30, 1])\n",
            "torch.Size([30, 1])\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Masking"
      ],
      "metadata": {
        "id": "5EcepOhR0Hzw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_square_subsequent_mask(sz,device=DEVICE):\n",
        "    mask = (torch.triu(torch.ones((sz, sz), device=device)) == 1).transpose(0, 1)\n",
        "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "    return mask\n",
        "\n",
        "def create_mask(src,device=DEVICE):\n",
        "    src_seq_len = src.shape[0]\n",
        "    src_mask = generate_square_subsequent_mask(src_seq_len)\n",
        "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
        "    return src_mask,src_padding_mask"
      ],
      "metadata": {
        "id": "3SPmc87rxh2i"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Positional Encoding"
      ],
      "metadata": {
        "id": "yqtmWGP52lxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# add positional information to the input tokens\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, emb_size: int, dropout: float, maxlen: int = 5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
        "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
        "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
        "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
        "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
        "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('pos_embedding', pos_embedding)\n",
        "\n",
        "    def forward(self, token_embedding: Tensor):\n",
        "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])"
      ],
      "metadata": {
        "id": "_ONcRC7_2npp"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Token Embedding"
      ],
      "metadata": {
        "id": "inQscUKl2o9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size: int, emb_size):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
        "        self.emb_size = emb_size\n",
        "\n",
        "    def forward(self, tokens: Tensor):\n",
        "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)"
      ],
      "metadata": {
        "id": "tvAa9tn-2rQ0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom GPT model architecture"
      ],
      "metadata": {
        "id": "FTpVx9CB4-w4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomGPTModel(nn.Module):\n",
        "    def __init__(self, embed_size,vocab_size, num_heads, num_layers, max_seq_len=500,dropout=0.1):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.init_weights()\n",
        "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
        "        self.positional_encoding = PositionalEncoding(embed_size, dropout=dropout)\n",
        "\n",
        "        print( embed_size )\n",
        "\n",
        "\n",
        "        # Remaining layers are part of the TransformerDecoder\n",
        "        encoder_layers = nn.TransformerEncoderLayer(d_model=embed_size, nhead=num_heads, dropout=dropout)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)\n",
        "        self.embed_size = embed_size\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "\n",
        "    def init_weights(self):\n",
        "      for p in self.parameters():\n",
        "          if p.dim() > 1:\n",
        "              nn.init.xavier_uniform_(p)\n",
        "\n",
        "    def create_mask(src,device=DEVICE):\n",
        "        src_seq_len = src.shape[0]\n",
        "        src_mask = nn.Transformer.generate_square_subsequent_mask(src_seq_len)\n",
        "        src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
        "        return src_mask,src_padding_mask\n",
        "\n",
        "    def decoder(self, x,src_mask):\n",
        "        seq_length = x.size(0)\n",
        "\n",
        "        # Add positional embeddings to the input embeddings\n",
        "        x = self.embed(x)* math.sqrt(self.embed_size)\n",
        "        x = self.positional_encoding(x)\n",
        "\n",
        "        if src_mask is None:\n",
        "            \"\"\"Generate a square causal mask for the sequence. The masked positions are filled with float('-inf').\n",
        "            Unmasked positions are filled with float(0.0).\n",
        "            \"\"\"\n",
        "            src_mask, src_padding_mask = create_mask(x)\n",
        "\n",
        "        output = self.transformer_encoder(x, src_mask)\n",
        "        logits = self.lm_head(x)\n",
        "        return logits\n",
        "\n",
        "    def forward(self,x,src_mask=None,key_padding_mask=None):\n",
        "\n",
        "        seq_length = x.size(0)\n",
        "\n",
        "        # Add positional embeddings to the input embeddings\n",
        "        x = self.embed(x)* math.sqrt(self.embed_size) #src = self.embedding(src) * math.sqrt(self.d_model)\n",
        "        x = self.positional_encoding(x)\n",
        "\n",
        "\n",
        "        if src_mask is None:\n",
        "            \"\"\"Generate a square causal mask for the sequence. The masked positions are filled with float('-inf').\n",
        "            Unmasked positions are filled with float(0.0).\n",
        "            \"\"\"\n",
        "            src_mask, src_padding_mask = create_mask(x)\n",
        "\n",
        "        output = self.transformer_encoder(x, src_mask,key_padding_mask)\n",
        "        x = self.lm_head(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "B77i8z5W4_n1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model configuration and initialization"
      ],
      "metadata": {
        "id": "gPWQgZILG1mH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ntokens = len(vocab)  # size of vocabulary\n",
        "emsize = 200  # embedding dimension\n",
        "nlayers = 2  # number of ``nn.TransformerEncoderLayer`` in ``nn.TransformerEncoder``\n",
        "nhead = 2  # number of heads in ``nn.MultiheadAttention``\n",
        "dropout = 0.2  # dropout probability\n",
        "\n",
        "model = CustomGPTModel(embed_size=emsize, num_heads=nhead, num_layers=nlayers, vocab_size=ntokens,dropout=dropout).to(DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXb-KKUDGzef",
        "outputId": "f42be2f3-2bd5-4aca-c630-179a3f121a86"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompting"
      ],
      "metadata": {
        "id": "-QuzM_bBG9uP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_prompt(prompt, block_size=BLOCK_SIZE):\n",
        "    # Handle None prompt\n",
        "    while prompt is None:\n",
        "        prompt = input(\"Sorry, prompt cannot be empty. Please enter a valid prompt: \")\n",
        "\n",
        "    tokens = tokenizer(prompt)\n",
        "    number_of_tokens = len(tokens)\n",
        "\n",
        "    # Handle long prompts\n",
        "    if number_of_tokens > block_size:\n",
        "        tokens = tokens[-block_size:]  # Keep last block_size characters\n",
        "\n",
        "    prompt_indices = vocab(tokens)\n",
        "    prompt_encoded = torch.tensor(prompt_indices, dtype=torch.int64).reshape(-1, 1)\n",
        "    return prompt_encoded\n",
        "\n",
        "\n",
        "prompt_encoded=encode_prompt(\"This is a prompt to get model generate next words.\").to(DEVICE)\n",
        "prompt_encoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mOdwSs1G9c_",
        "outputId": "822ee983-854b-4c12-c9bc-326ece8ad20f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   15],\n",
              "        [   11],\n",
              "        [    6],\n",
              "        [33700],\n",
              "        [   10],\n",
              "        [   86],\n",
              "        [ 2076],\n",
              "        [ 5673],\n",
              "        [  388],\n",
              "        [  665],\n",
              "        [    3]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits = model.decoder(prompt_encoded,src_mask=None).to(DEVICE).transpose(0, 1)\n",
        "logit_preiction =logits[:,-1]\n",
        "_, next_word_index = torch.max(logit_preiction, dim=1)\n",
        "index_to_en(next_word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "aa73RbZ_H4Ca",
        "outputId": "84ca5048-fc7a-4008-de09-5f794d21ba4d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'distortion'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Autoregressive text generation"
      ],
      "metadata": {
        "id": "Tq2Y0CT1LAJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#auto-regressive Language Model text generation\n",
        "def generate(model, prompt=None, max_new_tokens=500, block_size=BLOCK_SIZE, vocab=vocab, tokenizer=tokenizer):\n",
        "    # Move model to the specified device (e.g., GPU or CPU)\n",
        "    model.to(DEVICE)\n",
        "\n",
        "    # Encode the input prompt using the provided encode_prompt function\n",
        "    prompt_encoded = encode_prompt(prompt).to(DEVICE)\n",
        "    tokens = []\n",
        "\n",
        "    # Generate new tokens up to max_new_tokens\n",
        "    for _ in range(max_new_tokens):\n",
        "        # Decode the encoded prompt using the model's decoder\n",
        "        logits = model(prompt_encoded,src_mask=None,key_padding_mask=None)\n",
        "\n",
        "        # Transpose the logits to bring the sequence length to the first dimension\n",
        "        logits = logits.transpose(0, 1)\n",
        "\n",
        "        # Select the logits of the last token in the sequence\n",
        "        logit_prediction = logits[:, -1]\n",
        "\n",
        "        # Choose the most probable next token from the logits(greedy decoding)\n",
        "        next_token_encoded = torch.argmax(logit_prediction, dim=-1).reshape(-1, 1)\n",
        "\n",
        "        # If the next token is the end-of-sequence (EOS) token, stop generation\n",
        "        if next_token_encoded.item() == EOS_IDX:\n",
        "            break\n",
        "\n",
        "        # Append the next token to the prompt_encoded and keep only the last 'block_size' tokens\n",
        "        prompt_encoded = torch.cat((prompt_encoded, next_token_encoded), dim=0)[-block_size:]\n",
        "\n",
        "        # Convert the next token index to a token string using the vocabulary\n",
        "        # Move the tensor back to CPU for vocab lookup if needed\n",
        "        token_id = next_token_encoded.to('cpu').item()\n",
        "        tokens.append(vocab.get_itos()[token_id])\n",
        "\n",
        "    # Join the generated tokens into a single string and return\n",
        "    return (prompt + ' '.join(tokens))\n",
        "\n",
        "\n",
        "generate(model,prompt=\"this is the beginning of \",max_new_tokens=30,vocab=vocab,tokenizer=tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "WxgKQS8gLA2C",
        "outputId": "9acd98df-a7fb-44bf-f021-f89271fbeb01"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'this is the beginning of distaste under-acting centre oralist bricked idolize 2003 herrmann eyeing spradling symmetric pentecost restraining asking qualifiers shamus bleibtreau regretful callous bush pulsating dave propositions slopped freaky jokes/set-ups dumping visors accidentee *want*'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "difMradaLynP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import CrossEntropyLoss\n",
        "loss_fn = CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "\n",
        "def evaluate(model: nn.Module, eval_data) -> float:\n",
        "    model.eval()  # turn on evaluation mode\n",
        "    total_loss = 0.\n",
        "    with torch.no_grad():\n",
        "        for src,tgt in eval_data:\n",
        "            tgt = tgt.to(DEVICE)\n",
        "            #seq_len = src.size(0)\n",
        "            logits = model(src,src_mask=None,key_padding_mask=None)\n",
        "            total_loss +=  loss_fn(logits.reshape(-1, logits.shape[-1]), tgt.reshape(-1)).item()\n",
        "    return total_loss / (len(list(eval_data)) - 1)\n",
        "\n",
        "\n",
        "evaluate(model,val_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNtxLx4OLQ2k",
        "outputId": "b0f6eaf0-9c8a-47c8-e076-ee1f9d87d6d7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35.535376511801196"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = Adam(model.parameters(), lr=1e-2, weight_decay=0.01, betas=(0.9, 0.999))\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 10000, gamma=0.9)\n",
        "\n",
        "def train(model: nn.Module,train_data) -> None:\n",
        "    model.train()  # turn on train mode\n",
        "    total_loss = 0.\n",
        "    log_interval = 10000\n",
        "    start_time = time.time()\n",
        "\n",
        "    num_batches = len(list(train_data)) // block_size\n",
        "    for batch,srctgt in enumerate(train_data):\n",
        "        src= srctgt[0]\n",
        "        tgt= srctgt[1]\n",
        "        logits = model(src,src_mask=None)\n",
        "        logits_flat = logits.reshape(-1, logits.shape[-1])\n",
        "        loss = loss_fn(logits_flat, tgt.reshape(-1))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        if (batch % log_interval == 0 and batch > 0) or batch==42060:\n",
        "            lr = scheduler.get_last_lr()[0]\n",
        "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
        "            #cur_loss = total_loss / log_interval\n",
        "            cur_loss = total_loss / batch\n",
        "            ppl = math.exp(cur_loss)\n",
        "            print(f'| epoch {epoch:3d} | {batch//block_size:5d}/{num_batches:5d} batches | '\n",
        "                  f'lr {lr:02.4f} | ms/batch {ms_per_batch:5.2f} | '\n",
        "                  f'loss {cur_loss:5.2f} | ppl {ppl:8.2f}')\n",
        "            start_time = time.time()\n",
        "\n",
        "    return total_loss"
      ],
      "metadata": {
        "id": "TzJDDH5UQpog"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_loss = float('inf')\n",
        "epochs = 5\n",
        "Train_losses= []\n",
        "Val_losses = []\n",
        "for epoch in range(1, epochs + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    train_loss = train(model,dataloader)\n",
        "    val_loss = evaluate(model, val_dataloader)\n",
        "    val_ppl = math.exp(val_loss)\n",
        "    Train_losses.append(train_loss)\n",
        "    Val_losses.append(val_loss)\n",
        "\n",
        "    elapsed = time.time() - epoch_start_time\n",
        "    print('-' * 89)\n",
        "    print(f'| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | '\n",
        "        f'valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}')\n",
        "    print('-' * 89)\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), 'model_best_val_loss.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6QqF87pQsmv",
        "outputId": "28f87367-b3a9-4fad-9c5c-04e59a40560e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |  1000/ 1250 batches | lr 0.0100 | ms/batch 16.15 | loss  8.35 | ppl  4214.38\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   1 | time: 276.83s | valid loss  8.26 | valid ppl  3881.88\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   2 |  1000/ 1250 batches | lr 0.0100 | ms/batch 16.00 | loss  8.22 | ppl  3721.72\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   2 | time: 275.78s | valid loss  8.27 | valid ppl  3902.57\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   3 |  1000/ 1250 batches | lr 0.0100 | ms/batch 16.06 | loss  8.22 | ppl  3702.00\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   3 | time: 275.60s | valid loss  8.13 | valid ppl  3410.40\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   4 |  1000/ 1250 batches | lr 0.0100 | ms/batch 15.95 | loss  8.21 | ppl  3686.04\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   4 | time: 274.70s | valid loss  8.30 | valid ppl  4027.68\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   5 |  1000/ 1250 batches | lr 0.0100 | ms/batch 16.00 | loss  8.20 | ppl  3640.00\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   5 | time: 274.48s | valid loss  8.28 | valid ppl  3929.24\n",
            "-----------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the number of epochs (assuming the lengths of train_losses and val_losses are equal)\n",
        "num_epochs = len(Train_losses)\n",
        "\n",
        "# Create a figure and a set of subplots\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Plot the training losses\n",
        "ax.plot(range(num_epochs), Train_losses, label='Training Loss', color='blue')\n",
        "\n",
        "# Plot the validation losses\n",
        "ax.plot(range(num_epochs), Val_losses, label='Validation Loss', color='orange')\n",
        "\n",
        "# Set the x-axis label\n",
        "ax.set_xlabel('Epoch')\n",
        "\n",
        "# Set the y-axis label\n",
        "ax.set_ylabel('Loss')\n",
        "\n",
        "# Set the title of the plot\n",
        "ax.set_title('Training and Validation Losses')\n",
        "\n",
        "# Add a legend to the plot\n",
        "ax.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "8g754Er2QvBm",
        "outputId": "ec828d5e-d0b1-4bc5-b99c-9a922b2f474c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the saved model"
      ],
      "metadata": {
        "id": "AA9NRJB0Q6BG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!wget 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/kyn1_OsXrzjef0xihlsXmg.pt'\n",
        "#model.load_state_dict(torch.load('kyn1_OsXrzjef0xihlsXmg.pt',map_location=torch.device('cpu')))"
      ],
      "metadata": {
        "id": "63alA5-uQztO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading GPT2 model from HuggingFace"
      ],
      "metadata": {
        "id": "QK7CYIuSQ7eX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the tokenizer and model\n",
        "tokenizer1 = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "\n",
        "# Define the input prompt\n",
        "#input_text = \"Once upon a time in a faraway land,\"\n",
        "input_text = \"the movie was\"\n",
        "\n",
        "# Tokenize the input text and prepare the input for the model\n",
        "input_ids = tokenizer1.encode(input_text, return_tensors=\"pt\")\n",
        "\n",
        "# Generate text using the model\n",
        "# Set the desired length of the generated text (max_length),\n",
        "# and other generation parameters like temperature, top_k, and top_p\n",
        "max_length = 15\n",
        "temperature = 0.7\n",
        "top_k = 50\n",
        "top_p = 0.95\n",
        "\n",
        "generated_ids = model.generate(\n",
        "    input_ids,\n",
        "    max_length=max_length,\n",
        "    temperature=temperature,\n",
        "    top_k=top_k,\n",
        "    top_p=top_p,\n",
        "    pad_token_id=tokenizer1.eos_token_id,\n",
        ")\n",
        "\n",
        "# Decode the generated text\n",
        "generated_text = tokenizer1.decode(generated_ids[0], skip_special_tokens=True)\n",
        "\n",
        "# Print the input prompt and the generated text\n",
        "print(f\"Input: {input_text}\")\n",
        "print(f\"Generated Text: {generated_text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245,
          "referenced_widgets": [
            "915c42f4b4aa45f7914c660af9782f61",
            "809295e957634e36bfae1c6a79ede1a9",
            "e031a36d87a74ce1a4c307e57415f79a",
            "fec5dfb9b5204f1696eb983f9cb22180",
            "2d3bb6ee57894c18b9b07bec3161a15e",
            "f302ab8769574cc082fb9980e2835d8f",
            "3d3fadf3e2ef4f43920412e82550b0f3",
            "d6d3ade00c384a1283b6f5322157ff75",
            "8599ac8d52b94b5fa95f8a5e2af1b858",
            "1b0cb2c0db7b479c85753773080e2d8e",
            "2923b35a1e234d6a941ef81df8bdaf50",
            "5de633ca4c98478a8fda840509e96b38",
            "6aaafad10f7649d09c4872fcb6af0481",
            "68713400d4ba4a05a26a54432ad8c387",
            "7bfd7cfafa074a9c80a53d2dac4647a2",
            "a23ab371e7bd46a6bd059c461c62d9c7",
            "320b0280ccf64a5b9ceb4251a773d2e0",
            "be0a5783b7ef4a81892c3e7dc71aca88",
            "875c8f2b61f042bb85681d35a3e11ed8",
            "4836585901e046d89335a769703619f7",
            "3390126b1b6b46038d029cf22e0cabb1",
            "b9d0a2d29a5447f9a39cd13761dfc265",
            "6a45608c6de3476788567369a228cad3",
            "fa6775b0647040f79207c342a7acd052",
            "4fed57f49bde4667b091baea3b1f9582",
            "88b7913f1d5a4706abc26560d579fa26",
            "133223a9747a4164a7f5b32823da40cc",
            "b7a4bf9100c6494ab30d5e699670c0ab",
            "5d141869bc9444a8aa2111889462f293",
            "623eaf2a9af84fa8b3dacd59dfbdf933",
            "5d055a560d914d24bf29a4aeccb91b8c",
            "bb33aec95e634c95954abfd7dfdec37c",
            "0b23a698397e4dbab806d63f9d2ce512",
            "5c51e0103edd494d9a15671e6c24b53a",
            "01b3dcb113c94cf78520a25b38ad8336",
            "23d11458222b4cb3b7acba11e972c8f3",
            "e7c382827e4240769c81895a62cc4fc4",
            "9e9b934577c844ffad48ad2138b83ffe",
            "83e0f357d9c6462d86fda2eaaa48e0f8",
            "5e309172a5d143bc9dbd499e93d9683f",
            "fa2427e6fe88488084d6af1853be0481",
            "d8a933e273f643459e91d46e006a0ca1",
            "4dc82e59fdd2459e9113a161963c79e0",
            "a51c5c81297043e981e9fe714c243488",
            "34c1897efd6c40b49d193d3392c03797",
            "697d11c571074982bdfbdea340dbcc57",
            "267fc628b1be4f1384d7d938db9e28f4",
            "e65312f418e64bc8b77a44b7368988a9",
            "fa9dfa0c9f6e4ea1a603efd273c7c858",
            "4ecccab28ca247358ac87a5bd57a3c42",
            "ea767a47fda3480b8074621518a92b46",
            "269c29cf146c4f909fe6510acceb766d",
            "40ef3589229744dab5ae769e71325d32",
            "42de51221ef7419eb2be782b12a2396f",
            "a31b2bee466242f18011da445cb0d8e3",
            "2beafaecd45640e3b73bd166e69caa62",
            "cc948dc8bb9e44869fa24975b9bf579e",
            "72fcb4ed790842dab5c1e29910cd022b",
            "e09f02baba8b47b0a79d2e8c03d451c9",
            "88a8f347397f4bca9223af8f360ceec4",
            "7c2b1bebb961404f87f841e8ec2e4f76",
            "21e191b2843b4bb0926d25ee4fd49932",
            "04bac1f7e17d42449893a00a28bf187e",
            "683daf51de85419888878539caf80f95",
            "8aa11cfa25ae47488fa61a0239fa91c0",
            "c3982b5bfbbd4c9cae0bff767d86d05c"
          ]
        },
        "id": "gPwgW2SGTr3F",
        "outputId": "d9f3f651-9345-4f4b-e5a2-a5524b5c2ce9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "915c42f4b4aa45f7914c660af9782f61"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5de633ca4c98478a8fda840509e96b38"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a45608c6de3476788567369a228cad3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c51e0103edd494d9a15671e6c24b53a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34c1897efd6c40b49d193d3392c03797"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2beafaecd45640e3b73bd166e69caa62"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: the movie was\n",
            "Generated Text: the movie was a bit of a disappointment, but it was a great movie\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A8xiSDJEdqyk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}