{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Direct Preference Optimization (DPO) Using Hugging Face"
      ],
      "metadata": {
        "id": "eMiik-U_Y3Rd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ur8go_LpYzRH"
      },
      "outputs": [],
      "source": [
        "!pip install torch==2.3.1\n",
        "!pip install --user trl==0.11.4 # for optimization training\n",
        "!pip install peft==0.14.0 # for creating LoRA architecture\n",
        "!pip install matplotlib==3.9.0\n",
        "!pip install pandas\n",
        "!pip install numpy==1.26.0\n",
        "!pip install --user datasets==3.2.0\n",
        "!pip install transformers==4.45.2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "import os\n",
        "import requests\n",
        "import tarfile\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "\n",
        "from peft import LoraConfig\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer,TrainingArguments, GPT2Tokenizer, set_seed, GenerationConfig\n",
        "from trl import DPOConfig, DPOTrainer"
      ],
      "metadata": {
        "id": "zei0WHJIZB1k"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create and Configure the Model and Tokenizer"
      ],
      "metadata": {
        "id": "hvmp1kjsZDXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
        "\n",
        "# As we are using LoRA, this will not be used\n",
        "model_ref = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Set the padding side to \"right\" to fix the overflow issue with FP16 training\n",
        "tokenizer.padding_side = \"right\"\n",
        "\n",
        "# Disable the use of the cache during the model's forward pass\n",
        "model.config.use_cache = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370,
          "referenced_widgets": [
            "0620fb19428549ba9676ae7b940755e0",
            "e45cbb0ef8884d5a976293e0b4c81fd6",
            "6f3a3e8a2890450996385f1f63183d76",
            "5073b0414ef84ea3aa6db77085e0a837",
            "f585539c9e2341c7a8bdd2c700c74937",
            "f2aa52718b244fe794ee684aa901996a",
            "15aaa5175b934c7b8e919a79280d907d",
            "8dc049dfef61488fb831aaba23497812",
            "f318247c65744d99b8b8d3d3db8ad3b5",
            "2c801f7ae3aa4de485629c26dd5c5aa2",
            "4fdaf8eee4aa49c9a6e439ffa21d68b8",
            "12fb49a68803464c83b3957478d298b1",
            "67846f881f114fc494e113ff5231644b",
            "204cde61d06d4906abcec30dd74cd3ca",
            "0ea5cdb6a38c496eae5792e8ce8ecf0d",
            "485ede59a2cf44009dc8388b909de6e6",
            "fd4835e144ef4361926a557f4427bb6b",
            "4ae3ce5c36d84043a2d75165dbd349f4",
            "7da9dbe1a1cf4d86bc587d8c9ce1c1f5",
            "eb286caf4c8248aabfbbb220b7bad332",
            "0f4f916d38ee4a6ca132dd8df4ae55d7",
            "bb82947e70304f32a314bd703fea25a6",
            "af52d15a3e3c4917929c61991c8c2374",
            "db0bbce315204ba98ee7a553a02f0dfa",
            "26481997376549d8b020863cc7868cf5",
            "fb58d1acb4c14cc38369946d7d902f60",
            "7b23ecc873ed4406834f7cdac751501e",
            "7d95091a308c4f4fbbfb075fe3a24805",
            "43f025cb25cf4f9889f936d0a1672455",
            "6df0839c627943a8a92d362c137cab0f",
            "52b3f56b1c644836b0c9ea6414ad105b",
            "a1c28a549c7f466c86e918b6fd5624ff",
            "921fb6b4259d4461b7c013c4db656672",
            "56272306bc534179bc2225b7c37ca847",
            "d874cd55a1a048c08ce40675fa992ca1",
            "31f753dd3a5342b18aef8f14f92681dd",
            "543485c9f2a641f98cc2806137df6e18",
            "ba07a2279c0448578f6520710d30804b",
            "00f278c3ee454e42b7bed4e365d13ba6",
            "970169c920164bd8adc1756df88bfb35",
            "93490e332df04aa9bd4f97a30072461c",
            "67b7f3bee8104bcba6f7f46c701fc1a8",
            "0424186f2e394230bf6225edbf6178d7",
            "a766b62ed3ad42da88c8d26f763cf37a",
            "cf85caf8f1a64aadbc6b86ce2315adf7",
            "fffb0712e91d4714bbbaea1c183ace72",
            "5c50d1433b50448a95aeda8daa1da5d3",
            "1a23b61b39b645fbba085ad905518aa9",
            "70033922e17c4d788ad757a37157f4b3",
            "d91fa1ffc6af4dffae4bd67529bd0314",
            "af1fbaf42fcb49f4a5961ee33919277f",
            "9e76f3d7b51c473a87db483d8699163d",
            "86eb96cab38b4fd6ae2edc63aa352a37",
            "78682f95136f446792bd6854484854fc",
            "57e826b0bb174287aa236f7b5362d87e",
            "14ba76f34f7748f78e5c649f576ae239",
            "765532d0cd104221a5372bbf2c64b45e",
            "586c167d7b524b5a9ec81c79c2642a04",
            "53258bf919c54e7da90078468d97f10d",
            "90d1abcb8a314f9f9cb56fb59302d812",
            "bad40f38fa28471da2745557999b7693",
            "3b98c4314ab44ed9b8d2bbd7bd7b1b6b",
            "cde7f0a044cf4483a0947e071d242648",
            "6b85c74cef4b43b2800438f7858a04e2",
            "43a7e7c32bee4bf5a736c71092e4e2a2",
            "85ec0be26d024f67a884bec27f418df6",
            "41cf2b4bcafb4d8aafe587c3ef586e94",
            "0572a88b60074f008d57b3a954ab0777",
            "a93c8b54feee450a99612fb31688d204",
            "c44117df7a1d4c1d94b4924e0239ab31",
            "7ed0a136650141f882ad51b85a037d1b",
            "35ac724a601a4802a4cafef63a964ce4",
            "cee564027d8d46bd82efca9005acd6b5",
            "ee729c1eacf44f949f167b4e4b28a894",
            "1e366fc1894f4080bb68bdb321b0ebbd",
            "efb05536d0eb4d6a8285771aa8950dce",
            "9bf892b4a5e548c386a46ccc11950d0f"
          ]
        },
        "id": "mRzR0zttZGe4",
        "outputId": "ad0fee2f-b71c-441d-e8fa-ac47ff3ba3df"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0620fb19428549ba9676ae7b940755e0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "12fb49a68803464c83b3957478d298b1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af52d15a3e3c4917929c61991c8c2374"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "56272306bc534179bc2225b7c37ca847"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf85caf8f1a64aadbc6b86ce2315adf7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "14ba76f34f7748f78e5c649f576ae239"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "41cf2b4bcafb4d8aafe587c3ef586e94"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u52dA7a6ZeY_",
        "outputId": "e7488ef2-b1f2-484d-d24f-3930188c166d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2SdpaAttention(\n",
              "          (c_attn): Conv1D(nf=2304, nx=768)\n",
              "          (c_proj): Conv1D(nf=768, nx=768)\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D(nf=3072, nx=768)\n",
              "          (c_proj): Conv1D(nf=768, nx=3072)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Quantized Model Configuration (not used in this notebook due to resource limitation)"
      ],
      "metadata": {
        "id": "lIDQ7rUJZj1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''## Quantized model --only available on GPU\n",
        "from transformers import BitsAndBytesConfig\n",
        "\n",
        "quantization_config = BitsAndBytesConfig(load_in_4bit=True,\n",
        "                                         bnb_4bit_use_double_quant=True,\n",
        "                                         bnb_4bit_quant_type=\"nf4\",\n",
        "                                         bnb_4bit_compute_dtype=torch.bfloat16)\n",
        "\n",
        "# Load GPT-2 model with the specified quantization configuration\n",
        "model = AutoModelForCausalLM.from_pretrained(\"gpt2\", quantization_config=quantization_config)\n",
        "model_ref = AutoModelForCausalLM.from_pretrained(\"gpt2\", quantization_config=quantization_config)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\"\n",
        "model.config.use_cache = False'''"
      ],
      "metadata": {
        "id": "0ymq5qcSZxXh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocess Data Set"
      ],
      "metadata": {
        "id": "x6tsXeuraCC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds = load_dataset(\"BarraHome/ultrafeedback_binarized\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401,
          "referenced_widgets": [
            "9d7bc7cf1f934c5eb94c9c58c52f9ba9",
            "97e4de6a8ae34ca98a4b8fff526a3f90",
            "f50cd0c1d952400f80eaeb31f52277c9",
            "72a12eee50a643aca5640338ea499fab",
            "20c714280cf745419cfe3d6f72be7a41",
            "ddb666d28d7b4a01a713f59f98679396",
            "0798e4fc38ba4f8d84940eac2cf32034",
            "730f07570ea545128d99ff951a0b4b24",
            "e5864d1735304557bd0e6e31d7296bc6",
            "c2a3ba8d172541e3a59059c4cb120514",
            "6a82e3f86ed745da980a4a5167c872d1",
            "cfe05d904b034cb1a03e7c3bfd75f394",
            "53ac3f65df7b4275bb7e43242c66ad79",
            "d8cb33bb734e4d0f8263eafc6050e47e",
            "f04a1a138e824d01b327d40d811d8d14",
            "88952eafbdd643d89800fb1f65a5a89f",
            "6e460a0b96984b8f9629a3774ba85d1a",
            "94769381006e4d56ba9daf770a241b3d",
            "ab75e569d9d3473e90e18b8308d6102a",
            "aad50e8e41b34ef69c07b9070e906406",
            "f6ff0652e4e243d4971cd3f1220e9451",
            "33b23599873b4a9ca1fa9622af62e1e4",
            "44186c3bba184f13a7b0805ecb4f8b89",
            "15cdb90a06a143b9aeb82e9ea46cabe4",
            "a52ab62dcdc348dc9951a31c88c07ecb",
            "66dfe542715c4a17aab483edf4ee24f5",
            "ca9d56d9e1464aa4a81a3f34324cdc14",
            "20c77250734345298a448e2ca97c88ca",
            "ee72f0ec89b44693bbcfacc5a050e2ce",
            "2ba3fd58c3d04943a0c0d9b5ea47a9a4",
            "e4a6748cefe942d0a5b7d934a6b4ea2b",
            "c9373b41786f4f9188ead0b72a3c5d4e",
            "f780c1573d1747b298340bb228418351",
            "8ae6fa1f9fef4566aba8fb79f88cf4af",
            "e0b603ad48544d27acfbde719355870d",
            "58b91f443f3241ec8421f6fbd13dd454",
            "e1550abfd7e44615bd16fe798867fac9",
            "69467bf7cfaa4339ac6a1587c7d1802e",
            "7e7abec5893c4cd49384dc163aeb4c3a",
            "21ef3a495f734bdca98570a38480ac7e",
            "120d2eb474e547ff8d9ec35daf2e2dc2",
            "ee158d6a6ba54f468adf754864d95744",
            "cc1204b0b9b2477dbc4ac0a407468c37",
            "bf37ee8bcb64424980422475ed1bd459",
            "cc80c6beebf8413e92ea17864912be23",
            "b8ea0f59c8cd46a2a8b2f290eb959436",
            "5a8041442c764153a572cdf4606eb4e8",
            "7d8ba1ecc8d74bfd8221fdf35d2503fc",
            "5a4dd017ca394d75904bacc8ba3e36fd",
            "ea38b8087fe049c09156d3db2a21a17f",
            "4c6c943316ab46ce9723822dc4a8d30c",
            "447731b992564377a632d95018d597de",
            "f095c5b8e054486996997582f1195538",
            "9c7a9173e51644838eaa37f170d5c4d7",
            "348002bc35ac4e46aff4575c636ed96a",
            "973a10e5090a436294c4e378520a5d1b",
            "35afab66fed64bec8e908d73c0625630",
            "89b108e7b724445693ccfd74a165fd9c",
            "9900e35c6df34940832a2927932e84eb",
            "bf03a93a2da24a1c838bbbacafb9a5ab",
            "1b9048ab181d40dd9cc84e3909fd3056",
            "0e84a497ebbb43dbbe227a3daad50a3f",
            "a24fbf7156a548d1acd7fdafb0122a3f",
            "0bec623285b54c40aab72abffb6a8ef0",
            "84a5a51503c0469b909b3a398eb02bb8",
            "70a7eee574a245cdb77b2523699de0cf",
            "40245ff1be5348f0a91fd7c37868b3ab",
            "5fb1d536f070414eb538963e298b16c6",
            "a72f55d9b2b447539703405fb755f1d7",
            "1b2dd858f2484d6496205950af89be57",
            "994d05b8b3494335b3c4c1ea7b55a99a",
            "cda0fa9b476a48ee9e62ec3ee319abdb",
            "73e0fa2cab5e41fa85e61cacc084de15",
            "a6e18905858f4c3282a1d57c991b2da0",
            "75dd9a8bf933427a969bcd04528e0aac",
            "5447518418ee41688e061dae34a3d836",
            "1dfd789876ff4c1595a92137606a1934",
            "29dbbcf972424b7c9e3365af986d2495",
            "9b1be3219e2d451ea24e6d7f1840383d",
            "ddd35540d5834de589622ea0c7489494",
            "fee1284dca9042bb8972de2899fd2e0b",
            "d1203d3f480743dbb25070dc2c8c034c",
            "9041db998b124778b6adf38cc7182b44",
            "22400ef8291f4bd4a5964a98f2bbf8b0",
            "80ce1330b413421486c22c3b61062e3d",
            "6e88e474968e4d84ace31308239e8e99",
            "31b88572ce7c426c99319c1bde1daece",
            "f613516f0bed4190b555f96977a21729",
            "b55036c7cffa4c0fafa87d85e8b19997",
            "3337d1ebeb3e4ab49bd5dcb9aade4bf0",
            "1c2e811e3d3c48f2812cbbf51f3e8730",
            "bee690d0d5e04dbdb4881659cde24bc5",
            "57515810997a40c5bff4c163fdb0c9db",
            "2276621a43d341629fbe7b8c2eedd98d",
            "ff733e7e619f45f182ee884671aa1fb8",
            "a4f137525b464dafb3d2eeaa4b9815dc",
            "f6fc9561e0e8487cb4eef7743c5cdf2d",
            "e6a795fdd16c4b29902170f27f0c7de7",
            "48f35665cd4245599e2c2cadbb7ffd17",
            "8f7b411172e146688ea805f61f34a240",
            "da125f579ab3418f99afce161792ae44",
            "7fb73bf8610d4e6a8d7ec9038738200f",
            "b58e7c105aad4d66af516d7083d1ab04",
            "34e87000b4f743da89709e976b893e76",
            "322ff0d359d446e7a68c11e58424cfd9",
            "6d86b93ea1d9462c817647760e0399c1",
            "af2233fc3c8a4b1191af76a6183ab58a",
            "7e57004a79034c1a90e3b4c057875375",
            "8ccfb661c79944b18b06151e9cb8126b",
            "6d089fb8def540ef8d5c564dd1c2b444",
            "43a52281469c48ed825207efc363a957",
            "12e6654e67d44443a38fe4ee86ae672f",
            "b3bd8ba250584c97bd416627b677a68c",
            "66e3a22322844053ad5eee931c0ec1f2",
            "bb24174480784bc5a19ddddc50670e22",
            "ace62badceef4320a28621ccb94465fd",
            "03794dae7e334f29bf0bee9da78ed8a8",
            "3767065968d54193bed647608d62c25a",
            "fa8b49033eb9476f8cca87660bc3a02a",
            "2f6b22386df44d4ba58c0f8c9abb3ce2",
            "870af6e2698744f0a915246bd948d842",
            "fb8e162754d245d29230a0b09aeadcd1",
            "58650906e0154baebd19a8571ed4a009",
            "b21b9b7c119e446b986770a1410147e3",
            "2d11ea2dae7e4028acce0964810f7f05",
            "41ef1622aefc4f7890ccf8106b788bdb",
            "740b94412b3e46a59d0783b3f1532dd9",
            "7e13cab4683a4ed8a6630842452371cd",
            "c97d9e0bbc0847a68b81473381e9f731",
            "600415f9dea44bdeaba82cb3af7a2cc2",
            "6cf2034ca7a9481e88339363f9ac195d",
            "15fb4ba4639540388cabea914f91daf2"
          ]
        },
        "id": "o7L47rIEaEVD",
        "outputId": "c2252c56-0620-4d25-c6db-90e9ba66a93b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d7bc7cf1f934c5eb94c9c58c52f9ba9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train_prefs-00000-of-00001.parquet:   0%|          | 0.00/226M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cfe05d904b034cb1a03e7c3bfd75f394"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test_prefs-00000-of-00001.parquet:   0%|          | 0.00/7.29M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "44186c3bba184f13a7b0805ecb4f8b89"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test_sft-00000-of-00001.parquet:   0%|          | 0.00/3.72M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8ae6fa1f9fef4566aba8fb79f88cf4af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train_gen-00000-of-00001.parquet:   0%|          | 0.00/184M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc80c6beebf8413e92ea17864912be23"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test_gen-00000-of-00001.parquet:   0%|          | 0.00/3.02M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "973a10e5090a436294c4e378520a5d1b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train_prefs split:   0%|          | 0/61135 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "40245ff1be5348f0a91fd7c37868b3ab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train_sft split:   0%|          | 0/61135 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "29dbbcf972424b7c9e3365af986d2495"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test_prefs split:   0%|          | 0/2000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b55036c7cffa4c0fafa87d85e8b19997"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test_sft split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f7b411172e146688ea805f61f34a240"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train_gen split:   0%|          | 0/61135 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "43a52281469c48ed825207efc363a957"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test_gen split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb8e162754d245d29230a0b09aeadcd1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds.keys(), ds[\"train_prefs\"][0].keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJudwAq5aKKy",
        "outputId": "f7a47b45-d4b0-40ef-83a7-b8956cc84cb9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(dict_keys(['train_prefs', 'train_sft', 'test_prefs', 'test_sft', 'train_gen', 'test_gen']),\n",
              " dict_keys(['prompt', 'prompt_id', 'chosen', 'rejected', 'messages', 'score_chosen', 'score_rejected']))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds[\"train_prefs\"][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suIB8XjqaND0",
        "outputId": "d3228803-b346-49d9-ad9c-d8036b9d82b1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'prompt': 'how can i develop a habit of drawing daily',\n",
              " 'prompt_id': '086b3e24f29b8956a01059f79c56db35d118a06fb6b844b095737d042795cd43',\n",
              " 'chosen': [{'content': 'how can i develop a habit of drawing daily',\n",
              "   'role': 'user'},\n",
              "  {'content': \"Developing a daily habit of drawing can be challenging but with consistent practice and a few tips, it can become an enjoyable and rewarding part of your daily routine. Here are some strategies to help you develop the habit of drawing daily:\\n\\n1. Set a specific time: Allocate a specific time of the day to draw. It could be in the morning, afternoon, or evening. Make drawing a part of your daily routine.\\n2. Set a specific duration: Determine the amount of time you want to spend on drawing each day. It can be as little as 10 minutes or as long as an hour. Be consistent with the duration to help build the habit.\\n3. Start small and simple: Don't try to create a masterpiece every day, start with simple and easy-to-do sketches. Focus on improving your skills gradually.\\n4. Use a variety of tools and mediums: Experiment with different tools like pencils, pens, markers, and different mediums like paper, canvas, or digital apps to keep your drawing practice interesting and engaging.\\n5. Take breaks and rest: Taking breaks and resting after some time of drawing can help you avoid burnout and stay motivated.\\n6. Challenge yourself: Set challenges like drawing objects from memory or a specific subject to improve your skills and keep your drawing practice interesting.\\n7. Track your progress: Keep a record of your daily drawing practice and track your progress. This can be a source of motivation and help you see how far you've come.\\n\\nRemember, developing a habit takes time and patience. Stay consistent with your drawing practice, be flexible and open to trying new things, and with time, you'll develop a habit of daily drawing that brings you joy and satisfaction.\",\n",
              "   'role': 'assistant'}],\n",
              " 'rejected': [{'content': 'how can i develop a habit of drawing daily',\n",
              "   'role': 'user'},\n",
              "  {'content': \"One way to develop a habit of drawing daily is to allocate a specific time interval for drawing each day, whether it's early in the morning or before going to bed at night. You can also find inspiration or motivation to draw by joining drawing communities, following artists on social media, or going out into nature and sketching what you see. Additionally, practicing drawing every day can help you improve your skills over time.\",\n",
              "   'role': 'assistant'}],\n",
              " 'messages': [{'content': 'how can i develop a habit of drawing daily',\n",
              "   'role': 'user'},\n",
              "  {'content': \"Developing a daily habit of drawing can be challenging but with consistent practice and a few tips, it can become an enjoyable and rewarding part of your daily routine. Here are some strategies to help you develop the habit of drawing daily:\\n\\n1. Set a specific time: Allocate a specific time of the day to draw. It could be in the morning, afternoon, or evening. Make drawing a part of your daily routine.\\n2. Set a specific duration: Determine the amount of time you want to spend on drawing each day. It can be as little as 10 minutes or as long as an hour. Be consistent with the duration to help build the habit.\\n3. Start small and simple: Don't try to create a masterpiece every day, start with simple and easy-to-do sketches. Focus on improving your skills gradually.\\n4. Use a variety of tools and mediums: Experiment with different tools like pencils, pens, markers, and different mediums like paper, canvas, or digital apps to keep your drawing practice interesting and engaging.\\n5. Take breaks and rest: Taking breaks and resting after some time of drawing can help you avoid burnout and stay motivated.\\n6. Challenge yourself: Set challenges like drawing objects from memory or a specific subject to improve your skills and keep your drawing practice interesting.\\n7. Track your progress: Keep a record of your daily drawing practice and track your progress. This can be a source of motivation and help you see how far you've come.\\n\\nRemember, developing a habit takes time and patience. Stay consistent with your drawing practice, be flexible and open to trying new things, and with time, you'll develop a habit of daily drawing that brings you joy and satisfaction.\",\n",
              "   'role': 'assistant'}],\n",
              " 'score_chosen': 8.5,\n",
              " 'score_rejected': 7.5}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reducing the volume of data (due to resource limitations) by selecting 50 samples\n",
        "for key in ds:\n",
        "    cnt=50\n",
        "    ds[key] = ds[key].select(range(cnt))\n",
        "\n",
        "def process(row):\n",
        "    del row[\"prompt_id\"]\n",
        "    del row[\"messages\"]\n",
        "    del row[\"score_chosen\"]\n",
        "    del row[\"score_rejected\"]\n",
        "    row[\"chosen\"] = row[\"chosen\"][-1][\"content\"]\n",
        "    row[\"rejected\"] = row[\"rejected\"][-1][\"content\"]\n",
        "    return row\n",
        "\n",
        "ds = ds.map(process, num_proc=multiprocessing.cpu_count(), load_from_cache_file=False,)\n",
        "train_dataset = ds['train_prefs']\n",
        "eval_dataset = ds['test_prefs']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209,
          "referenced_widgets": [
            "c081b7be15824b58809304d946cccb75",
            "3e0f078c334e4637990169fc944330b3",
            "05ed61757b2a4d0f9a573832a44bd2e4",
            "992c8c096de24c7eab337dd85c2235ed",
            "c47bdab6713d4486889316dabfce6eb7",
            "f5af95552b044ed9936347e9a839ae72",
            "55e64d2bd5ab47f087301e979335e82b",
            "29be6c24695a488ab9772039d2d2b917",
            "8446c6603c4745508fc0b6c0f2a07177",
            "55dfe798f4f844aca3e5c6cf40381c14",
            "3dedf7888ebf41459047a3058e89ad15",
            "13fb2fb66b384b5dadbc228508ff4e39",
            "158cdb731d4e48f3877976642e0d1262",
            "024508b9a4d944e483ed412bdd100a68",
            "71482a12d57c4dcaad0debec77c5c39d",
            "315c72aa758e43d0806a81a44aef51cb",
            "ef37317f801846098d5fdddaf687ab1b",
            "38437eb6abbf43a99e1d095a5d7fb0aa",
            "d4c8be96b38345ca8effd28c81557d95",
            "4a555511d64748d5915ef6f176ccff40",
            "528d90fbf811455e9f24dda4ff3a3d29",
            "dcf797fdcc8e490bb45ce5f6bb29154d",
            "18826f69a02647379650d0dddef443c4",
            "2b9f972e5f2e4b719106f4e85cf5c713",
            "cacdc661c9154bb9a98f39abf5d211e8",
            "2c6cb7cbc9c14eb99b7bc3523b78cda7",
            "18300ffaec6b48ac91e56362192763e4",
            "0e9463a9e8554a47bc2ffab195485b5e",
            "5046f05555fc4107b736abf83d032d0b",
            "b09d5121ab4c48a8b86e189384e8aeb1",
            "2a7af82a21a64e7ba74b838aca26a04f",
            "0132459337bc4bde8a1d4230fdf33142",
            "9ca4067146fd4d3a8ccbf13917378d37",
            "a7b458b283744b3f98b1afe2a658cc93",
            "0a2fd7d34b4f4dbea1f656478ba06a28",
            "a27304f063b340d8b113b2b8ba3f58f0",
            "c45f2f44045c4640984bcd6b5a05db99",
            "f0a43deb6a1643d49eb8461d18318b58",
            "d5466fde427f45ccb6312a1220b6d2b4",
            "9fee36cac50a4edbba3907ac0b3508d2",
            "c4a76f06c41f4505b1f07c3a5a8e2343",
            "72b34c11bbea40239a5bdce2a7a7e310",
            "49ef304aaa6547da86948b6c8f616432",
            "9785578640aa4e7b832afe98b3dbd117",
            "9013d97f7763469b938959b59db8bf82",
            "4475382326114870af0c27bdd8b2580e",
            "9afc7d43ac4a4550a6673e7cca442bad",
            "a3aede8cc99c4aea82e0d903f02dae84",
            "d1ead3d875174e758254d76ff63ec7a8",
            "fd4a16363a1847d688567c4c6a9ccd2b",
            "5a92d017348e4e2c9e343f7d2cd787f7",
            "8a3290f9c4504d6ba9fc0dbb6bae6066",
            "e559def3128540bd9ca810decc9431db",
            "214d686b1744432bbe0c4f573520e1da",
            "0590db38636f4f8bb5dc65bdba5c338e",
            "a9d60d7d06cc437b966a00a25103612a",
            "fe60f5bda88c42fd9dbc439f486689e7",
            "633b400f0a954ba0b5a2dd69d19fecc0",
            "a9b24bc00ceb485989fce3bbc979b995",
            "a0c37e8e303d417ca049a630a8299321",
            "167cc4e3eaf34ed285a992f542c149ef",
            "440afe05369f4174824ee9f8d8733b2b",
            "83c130d15a484c96ab356f3c56d4fc40",
            "7258671b44104c11b8dacb1ae7032f00",
            "4a73f0d8e68343b8b31ac7fe1e9dbd0a",
            "317eb2f50a63441a8c9ffc1f8f16e252"
          ]
        },
        "id": "sshLX_FjaNoS",
        "outputId": "aa14a429-7e75-4bec-ad17-35a7d4538090"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/50 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c081b7be15824b58809304d946cccb75"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/50 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "13fb2fb66b384b5dadbc228508ff4e39"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/50 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "18826f69a02647379650d0dddef443c4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/50 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a7b458b283744b3f98b1afe2a658cc93"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/50 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9013d97f7763469b938959b59db8bf82"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/50 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a9d60d7d06cc437b966a00a25103612a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pr0x70HrahQ8",
        "outputId": "76336f31-9b22-445c-e082-d3996a7b815f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'prompt': 'how can i develop a habit of drawing daily',\n",
              " 'chosen': \"Developing a daily habit of drawing can be challenging but with consistent practice and a few tips, it can become an enjoyable and rewarding part of your daily routine. Here are some strategies to help you develop the habit of drawing daily:\\n\\n1. Set a specific time: Allocate a specific time of the day to draw. It could be in the morning, afternoon, or evening. Make drawing a part of your daily routine.\\n2. Set a specific duration: Determine the amount of time you want to spend on drawing each day. It can be as little as 10 minutes or as long as an hour. Be consistent with the duration to help build the habit.\\n3. Start small and simple: Don't try to create a masterpiece every day, start with simple and easy-to-do sketches. Focus on improving your skills gradually.\\n4. Use a variety of tools and mediums: Experiment with different tools like pencils, pens, markers, and different mediums like paper, canvas, or digital apps to keep your drawing practice interesting and engaging.\\n5. Take breaks and rest: Taking breaks and resting after some time of drawing can help you avoid burnout and stay motivated.\\n6. Challenge yourself: Set challenges like drawing objects from memory or a specific subject to improve your skills and keep your drawing practice interesting.\\n7. Track your progress: Keep a record of your daily drawing practice and track your progress. This can be a source of motivation and help you see how far you've come.\\n\\nRemember, developing a habit takes time and patience. Stay consistent with your drawing practice, be flexible and open to trying new things, and with time, you'll develop a habit of daily drawing that brings you joy and satisfaction.\",\n",
              " 'rejected': \"One way to develop a habit of drawing daily is to allocate a specific time interval for drawing each day, whether it's early in the morning or before going to bed at night. You can also find inspiration or motivation to draw by joining drawing communities, following artists on social media, or going out into nature and sketching what you see. Additionally, practicing drawing every day can help you improve your skills over time.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LoRA Configuration"
      ],
      "metadata": {
        "id": "1Sz3vxrQamGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "peft_config = LoraConfig(r=4, target_modules=['c_proj','c_attn'],\n",
        "                         task_type=\"CAUSAL_LM\", lora_alpha=8,\n",
        "                         lora_dropout=0.1, bias=\"none\")"
      ],
      "metadata": {
        "id": "CxJospgjam-_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DPO Configuration"
      ],
      "metadata": {
        "id": "WCYJUig1a0yC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import get_peft_model\n",
        "training_args = DPOConfig(beta=0.1,  # temperature parameter for the DPO loss(0.1-0.5)\n",
        "                          output_dir=\"dpo\", num_train_epochs=5, per_device_train_batch_size=1,\n",
        "                          per_device_eval_batch_size=1, remove_unused_columns=False,\n",
        "                          logging_steps=10,  # number of steps between logging training progress\n",
        "                          gradient_accumulation_steps=1, learning_rate=1e-4,\n",
        "                          evaluation_strategy=\"epoch\",  # after each step or epoch)\n",
        "                          warmup_steps=2, fp16=False,  # 16-bit (float16) precision\n",
        "                          save_steps=500,  # saving checkpoints\n",
        "                          report_to='none')  # The reporting backend to use (set to 'none' to disable, also report to wandb or tensorboard)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nd1mAoTay_T",
        "outputId": "7a7f4dac-3022-4530-f3ea-a3ee4dccf346"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DPO Training"
      ],
      "metadata": {
        "id": "FUHHNhYlcTVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = DPOTrainer(model=model, ref_model=None, args=training_args, train_dataset=train_dataset,\n",
        "                     eval_dataset=eval_dataset, tokenizer=tokenizer, peft_config=peft_config,\n",
        "                     #max_prompt_length=512,\n",
        "                     max_length=512) # maximum sequence length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302,
          "referenced_widgets": [
            "f511693542574951a2aa01e6a5dacf7f",
            "bca28f9be3d843eabf94b174f4ef4724",
            "714d99308e8b4c14acb67e088ab895aa",
            "964ccdc7b9394a409e5aa26da2ea6cda",
            "8d6bc8fea541492591cdbaba2ac20e70",
            "aafac40f0e034110bf6ab6f24ab53861",
            "8c6eb8eefcc74d0796ea2540cddb9d0f",
            "80dc9f009d044d3aa1e086dc33baf161",
            "c3bdfe1d7c1f4c799bbd5fbb3f22b2d4",
            "2bc3322227514387a4eaae9af7a78ded",
            "a1ab42b5fdd54c67b9caa8fa4fb25861",
            "dec0c36c61e042ed838084313990b7a7",
            "866527138dca4f4997f92e55f942b060",
            "d70073748dd3482382da03c0ef2bb9f2",
            "9a60ae5d1e324866ae2d971bccd89a75",
            "9cb592a1c2574cf0b72da494150ce933",
            "3692cc03d12e49fb96ad639f602d4e5a",
            "b43860c28aa441b09bb99d00e2bdc6b2",
            "140480fddc454f83988825333ecba901",
            "e6ec957f78f548bcb8875bddf51f75ff",
            "2b4cfaaefdfe4d2688ad873a6d8dce9a",
            "bc1e219aaeef4604b5dc96853fd5f489"
          ]
        },
        "id": "TI4rR3DjcQEL",
        "outputId": "ce9b6392-e9c6-47ee-bffb-cfc0475f9bd9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_length. Will not be supported from version '1.0.0'.\n",
            "\n",
            "Deprecated positional argument(s) used in DPOTrainer, please use the DPOConfig to set these arguments instead.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/layer.py:1264: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
            "  warnings.warn(\n",
            "/root/.local/lib/python3.11/site-packages/trl/trainer/dpo_trainer.py:655: UserWarning: You passed `max_length` to the DPOTrainer, the value you passed will override the one in the `DPOConfig`.\n",
            "  warnings.warn(\n",
            "/root/.local/lib/python3.11/site-packages/trl/trainer/dpo_trainer.py:673: UserWarning: `max_prompt_length` is not set in the DPOConfig's init it will default to `128` by default, but you should do it yourself in the future.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing train dataset:   0%|          | 0/50 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f511693542574951a2aa01e6a5dacf7f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1154 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing eval dataset:   0%|          | 0/50 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dec0c36c61e042ed838084313990b7a7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Model"
      ],
      "metadata": {
        "id": "88FnjubMc0qa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I didn't run this cell because it is time-consuming as I am running the notebook on CPU."
      ],
      "metadata": {
        "id": "bdoUcR7_c3hS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "yku9cs0NcxyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python --v"
      ],
      "metadata": {
        "id": "l3wMEpypdIla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(hasattr(model, \"generate\"))"
      ],
      "metadata": {
        "id": "38eZMzAfdK_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dpo_model = AutoModelForCausalLM.from_pretrained('./dpo/checkpoint-250')"
      ],
      "metadata": {
        "id": "mYeLwRDKdOfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading Trained Model (as an Alternative to train it on GPU)"
      ],
      "metadata": {
        "id": "lrwK9i_pdPpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/YIDeT3qihEpWChdXN_RmTg/DPO-tar.gz'\n",
        "filename = './DPO.tar'\n",
        "\n",
        "response = requests.get(url)\n",
        "with open(filename, 'wb') as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "if tarfile.is_tarfile(filename):\n",
        "    with tarfile.open(filename, 'r') as tar:\n",
        "        tar.extractall()\n",
        "        print(\"Files extracted:\", tar.getnames())\n",
        "else:\n",
        "    print(\"The adownloaded file is not a tar file.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kl5nrjWjdW3s",
        "outputId": "2fb0c1f9-b3fe-4443-8f76-26d56ec8b088"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files extracted: ['DPO', 'DPO/adapter_config.json', 'DPO/tokenizer_config.json', 'DPO/merges.txt', 'DPO/adapter_model.safetensors', 'DPO/special_tokens_map.json', 'DPO/training_args.bin', 'DPO/README.md', 'DPO/vocab.json']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dpo_model = AutoModelForCausalLM.from_pretrained('./DPO')"
      ],
      "metadata": {
        "id": "dBRIkZ_vdbUC"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generation"
      ],
      "metadata": {
        "id": "G1aMdEDaddvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42)\n",
        "\n",
        "generation_config = GenerationConfig(do_sample=True, # to generate diverse text\n",
        "                                     top_k=1, temperature=0.1, max_new_tokens=25, pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "PROMPT = \"Is a higher octane gasoline better for your car?\"\n",
        "inputs = tokenizer(PROMPT, return_tensors='pt')\n",
        "outputs = dpo_model.generate(**inputs, generation_config=generation_config)\n",
        "print(\"DPO response:\\t\",tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
        "\n",
        "gpt2_model = AutoModelForCausalLM.from_pretrained('gpt2')\n",
        "outputs = gpt2_model.generate(**inputs, generation_config=generation_config)\n",
        "print(\"\\nGPT2 response:\\t\",tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUWxX-DrddMh",
        "outputId": "02ae536c-20c1-41a6-8cef-225f7057cdd9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DPO response:\t Is a higher octane gasoline better for your car?\n",
            "\n",
            "The answer is yes. The higher octane gasoline is better for your car.\n",
            "\n",
            "The higher octane gasoline\n",
            "\n",
            "GPT2 response:\t Is a higher octane gasoline better for your car?\n",
            "\n",
            "The answer is yes. The higher octane gasoline is more efficient and more fuel efficient.\n",
            "\n",
            "The higher oct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The model is trained on a small data for 5 epochs only."
      ],
      "metadata": {
        "id": "sWs2JfoHeDAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"argilla/ultrafeedback-binarized-preferences-cleaned\")\n",
        "dataset['train']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_nThRYOd4JB",
        "outputId": "3ffb1479-3517-47f5-e40b-0b9117fbd79c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['source', 'prompt', 'chosen', 'chosen-rating', 'chosen-model', 'rejected', 'rejected-rating', 'rejected-model'],\n",
              "    num_rows: 60917\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnt = 10000\n",
        "dataset['train'] = dataset['train'].select(range(cnt))\n",
        "\n",
        "def process(row):\n",
        "    del row[\"source\"]\n",
        "    del row[\"chosen-rating\"]\n",
        "    del row[\"chosen-model\"]\n",
        "    del row[\"rejected-rating\"]\n",
        "    del row[\"rejected-model\"]\n",
        "    row[\"chosen\"] = row[\"chosen\"][-1][\"content\"]\n",
        "    row[\"rejected\"] = row[\"rejected\"][-1][\"content\"]\n",
        "    return row\n",
        "\n",
        "dataset['train'] = dataset['train'].map(process, num_proc=multiprocessing.cpu_count(), load_from_cache_file=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "b9019d9080c04cd9b0baf3a379cbd296",
            "c1c457019280446f952d236b779132a3",
            "6f5dd0f7a6c340cebd4636ac6bff26b5",
            "66f062be84a946bdaa732a9b8e4859f5",
            "cfe09d31925a4220ac19d27c1f374185",
            "79eaf9ebe43545eea0e4bcb89d7bce9f",
            "8bf9df0a854b438c82ea4dfe4d4f4097",
            "d6cee5c52d424d1bbbeed91461c4e775",
            "07f039a40d514b0b971d4c8a97e498ac",
            "25ed70e883f84b4c8c7c7582a6f7a872",
            "66de215e562b4594a9b23c221edce5e1"
          ]
        },
        "id": "61fqqObxeLuf",
        "outputId": "1b0ffa54-21b6-45c4-9b5e-543cf06095f3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9019d9080c04cd9b0baf3a379cbd296"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.8 * len(dataset['train']))\n",
        "eval_size = len(dataset['train']) - train_size\n",
        "\n",
        "train_dataset = dataset['train'].select(range(train_size))\n",
        "eval_dataset = dataset['train'].select(range(train_size, train_size + eval_size))\n",
        "\n",
        "train_dataset, train_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nePhh_N3eXjn",
        "outputId": "311d5ec7-5a23-4fd3-81c3-9f5f28b5c404"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Dataset({\n",
              "     features: ['prompt', 'chosen', 'rejected'],\n",
              "     num_rows: 8000\n",
              " }),\n",
              " {'prompt': 'Can you write a C++ program that prompts the user to enter the name of a country and checks if it borders the Mediterranean Sea? Here\\'s some starter code to help you out:\\n#include <iostream>\\n#include <string>\\nusing namespace std;\\nint main() {\\n    string country;\\n    // prompt user for input\\n    cout << \"Enter the name of a country: \";\\n    cin >> country;\\n    // check if country borders the Mediterranean Sea\\n    // [C++ code]\\n    return 0;\\n}',\n",
              "  'chosen': 'Here\\'s a C++ program that prompts the user to enter the name of a country and checks if it borders the Mediterranean Sea:\\n\\n#include <iostream>\\n#include <string>\\n#include <set>\\n#include <map>\\n#include <algorithm>\\n\\nusing namespace std;\\n\\nint main() {\\n    // store countries and their bordering seas in a map\\n    map<string, set<string>> countries;\\n    countries[\"Algeria\"] = {\"Mediterranean Sea\", \"North African Coast\"};\\n    countries[\"France\"] = {\"Mediterranean Sea\", \"English Channel\"};\\n    countries[\"Italy\"] = {\"Mediterranean Sea\", \"Adriatic Sea\"};\\n    countries[\"Malta\"] = {\"Mediterranean Sea\", \"North African Coast\"};\\n    countries[\"Spain\"] = {\"Mediterranean Sea\", \"Atlantic Ocean\"};\\n    countries[\"Tunisia\"] = {\"Mediterranean Sea\", \"North African Coast\"};\\n\\n    string country;\\n    cout << \"Enter the name of a country: \";\\n    cin >> country;\\n\\n    // check if country is in the map\\n    if (countries.find(country)!= countries.end()) {\\n        // check if country borders the Mediterranean Sea\\n        set<string> borders = countries.at(country);\\n        if (borders.find(\"Mediterranean Sea\")!= borders.end()) {\\n            cout << country << \" borders the Mediterranean Sea.\" << endl;\\n        } else {\\n            cout << country << \" does not border the Mediterranean Sea.\" << endl;\\n        }\\n    } else {\\n        cout << country << \" is not a recognized country.\" << endl;\\n    }\\n\\n    return 0;\\n}\\n\\nIn this program, we first define a map called countries that stores each country\\'s name as a key and a set of its surrounding seas as the value. We use a set to store each sea name so that we can easily check if a country borders a certain sea.\\n\\nWe then present the user with a prompt to enter the name of a country. We use a while loop to ensure that the user enters a valid country name. We check if the country is in the map, and if so, we retrieve its bordering seas from the map.\\n\\nFinally, we check if the Mediterranean Sea is among the set of borders. If it is, we inform the user that the country borders the Mediterranean Sea. If not, we inform the user that the country does not border the Mediterranean Sea.',\n",
              "  'rejected': 'Sure, here is the program using the C++11 algorithm \"cds::algorithm::GreaterEqual\":\\n#include <iostream>\\n#include <string>\\n#include <algorithm>\\n#include <vector>\\n#include <cctype>\\n\\nusing namespace std;\\n\\nint main() {\\n    string country;\\n    cout << \"Enter the name of a country: \";\\n    cin >> country;\\n    std::vector<string> vec;\\n    vec.push_back(country);\\n    size_t index = std::find_if(vec.begin(), vec.end(), [](const string& s) {\\n        return std::any_of(s.begin(), s.end(), [](const char& c) {\\n            return c == \\'}}\\';\\n    });\\n    if (index != vec.end()) {\\n        if ((*index)[0] == \\'M\\') {\\n            cout << \"Country is bordered by the Mediterranean Sea.\" << endl;\\n        } else {\\n            cout << \"Country does not border the Mediterranean Sea.\" << endl;\\n        }\\n    } else {\\n        cout << \"Country is not found.\" << endl;\\n    }\\n    return 0;\\n}'})"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT = input()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYHv9YHrepwu",
        "outputId": "5057f60e-4f14-471c-e6f2-8a58e7b191cc"
      },
      "execution_count": 43,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What are the 5 most spoken languages in the world?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "generation_config = GenerationConfig(do_sample=True, top_k=50, temperature=0.7, max_new_tokens=50, pad_token_id=tokenizer.eos_token_id)"
      ],
      "metadata": {
        "id": "tYg6Ho4ceuOz"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_dpo_response(prompt):\n",
        "    inputs = tokenizer(prompt, return_tensors='pt')\n",
        "    outputs = dpo_model.generate(**inputs, generation_config=generation_config)\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "def generate_gpt2_response(prompt):\n",
        "    inputs = tokenizer(prompt, return_tensors='pt')\n",
        "    outputs = gpt2_model.generate(**inputs, generation_config=generation_config)\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "dpo_response = generate_dpo_response(PROMPT)\n",
        "gpt2_response = generate_gpt2_response(PROMPT)\n",
        "\n",
        "print(\"DPO response:\\t\", dpo_response)\n",
        "print(\"\\nGPT-2 response:\\t\", gpt2_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X61bXsDTe2RK",
        "outputId": "cede2d14-6e3f-4939-de35-a4ca15098e52"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DPO response:\t What are the 5 most spoken languages in the world?\n",
            "\n",
            "A: English, French, Italian, Spanish .\n",
            "\n",
            ". English, French, Italian, Spanish . A lot of people like me, but I don't take it quite as seriously as I would like.\n",
            "\n",
            ". People like me\n",
            "\n",
            "GPT-2 response:\t What are the 5 most spoken languages in the world?\n",
            "\n",
            "English:\n",
            "\n",
            "\"English is the language of peace, and it is the language that we live by. It is the language of war. It is the language of tyranny. It is the language of oppression. It is the language of\n"
          ]
        }
      ]
    }
  ]
}
